# How to dispatch 3000 HTTPS requests/second on a $6 VM

The blog engine running this page gets rid of any database. It loads all the
contents from the disk, renders the Markdown files, and stores them along with
the rest of binary files in an LRU cache that, given the small size of this blog,
fits in some megabytes of memory.

Given the small traffic that this blog has (few tenths of users every day), my
$6/month [droplet at DigitalOcean](https://www.digitalocean.com/) is usually
under 3% of its single vPCU consumption and at 50% of its 1GB of memory.
Concretely, according to my [New Relic Infrastructure monitor](https://newrelic.com),
the `goblog` process running this blog is normally near 0% of memory and using
around 50MB of memory (for both the code and the cached data).

Sometimes I can see small peaks when a post reached sites like e.g. Reddit or
HackerNews. But never spent a significant amount of resources. So a question
arose to my mind: how many requests/second would my blog be able to dispatch
with decent response times?

Responding to that question allowed me to start learning the basics of [K6](https://k6.io/),
to simulate the connection of multiple users to different pages of my blog.

So I first created this Javascript file:

```javascript
import http from 'k6/http';
import {sleep} from 'k6';

export const options = {
  vus: 200,
  duration: '5m',
};


const urlGroups = [ /* list of URLs */ ];

export default function () {
  let idx = Math.floor(Math.random() * urlGroups.length);
  let urlGroup = urlGroups[idx];
  urlGroup.forEach(http.get);
}
```

The `urlGroups` is a 2D array where each first-level entry is a URL to any
of the pages. Each entry is an array to the URLs of the payloads that a typical
browser would get. For example each second-level array would contain the URLs
for the blog post plus the URLs to the files.

The `options` array means that we would simulate 200 virtual users (VUs)
continuously connecting to any random entry in the `urlGroups` list.

You can run this script from your laptop, but probably you won't be able to send
enough load to a single server, so I installed the [K6 operator](https://github.com/grafana/k6-operator)
on a 3x16CPUs Kubernetes cluster, copied the previous script in the ConfigMap
and deployed the following file:

```yaml
apiVersion: k6.io/v1alpha1
kind: K6
metadata:
  name: k6-sample
spec:
  parallelism: 48
  script:
    configMap:
      name: my-stress-test
      file: script.js
```

So 

agregando stuff:

```text
oc get jobs
oc logs -l k6_cr=k6-sample --tail=20 > file.txt
grep http_reqs reqs_200_48.txt | awk '{ print $2 }' | awk '{sum += $1;} END {print sum;}'
grep data_received results_1000_p48.txt | awk '{ print $2 }' | awk '{sum += $1;} END {print sum;}'

5m 

1000 vus with 48 parallelization
total requests: 877218
reqs/sec: 2924
http_req_duration: avg=339.34ms min=91.05ms med=298.96ms max=2.63s    p(90)=460.35ms p(95)=519.59ms
total megas descargado: 33109

200 vus with 48 parallelization
total: 630307
reqs/seq: 2100
http_req_duration..............: avg=94.49ms  min=89.2ms  med=93.74ms  max=470.08ms p(90)=98.04ms  p(95)=103.22ms
```

ojito que con los tests te puedes fundir el l√≠mite de 1000GB transfer
